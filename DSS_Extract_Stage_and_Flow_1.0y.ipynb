{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydsstools.heclib.dss import HecDss\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.plotting import figure, save, gridplot\n",
    "from bokeh.io import output_file\n",
    "from bokeh.models import ColumnDataSource, Legend, LegendItem, HoverTool\n",
    "\n",
    "folder_path = \"C:/DSS FILE OUTPUTS/DSS-Sensitivity\"\n",
    "gauge_data_path = os.path.join(folder_path, \"Gauge_Data.csv\")\n",
    "river_stations, search_word, pathname_pattern, start_date, end_date = [\"90128\", \"117188\", \"110659\", \"7458\"], \"Harvey\", \"/*/*/*/*/*/*/\", \"26AUG2017 00:00:00\", \"14SEP2017 00:00:00\"\n",
    "\n",
    "def check_identical_values(df, new_series):\n",
    "    for column in df.columns:\n",
    "        if np.array_equal(df[column].head(100).values, new_series.head(100).values):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".dss\"):\n",
    "        with HecDss.Open(os.path.join(folder_path, file)) as fid:\n",
    "            path_list = fid.getPathnameList(pathname_pattern, sort=1)\n",
    "            filtered_path_list = [\n",
    "                path for path in path_list\n",
    "                if any(station in path for station in river_stations)\n",
    "                and search_word in path\n",
    "                and (\"FLOW\" in path or \"STAGE\" in path)\n",
    "                and \"FLOW-CUM\" not in path\n",
    "            ]\n",
    "            for pathname in filtered_path_list:\n",
    "                ts = fid.read_ts(pathname, window=(start_date, end_date), trim_missing=True)\n",
    "                if ts is not None:\n",
    "                    times, values = np.array(ts.pytimes), ts.values\n",
    "                    header = f\"{file} {pathname}\"\n",
    "                    temp_df = pd.DataFrame({header: pd.Series(values[~ts.nodata], index=times[~ts.nodata])})\n",
    "                    if not check_identical_values(df, temp_df[header]):\n",
    "                        df = pd.concat([df, temp_df], axis=1)\n",
    "\n",
    "df.to_csv(os.path.join(folder_path, \"output_raw.csv\"), index_label=\"Date\")\n",
    "\n",
    "grouped_data = {(split_label[2], \"STAGE\" if \"STAGE\" in split_label[3] else \"FLOW\"): [] for column in df.columns for split_label in [column.split('/')]}\n",
    "for column in df.columns:\n",
    "    split_label = column.split('/')\n",
    "    grouped_data[(split_label[2], \"STAGE\" if \"STAGE\" in split_label[3] else \"FLOW\")].append(df[column])\n",
    "\n",
    "gauge_data = pd.read_csv(gauge_data_path, header=None, nrows=3)\n",
    "metadata = {key: gauge_data.iloc[idx, 1:].tolist() for idx, key in enumerate([\"River Station\", \"STAGE or FLOW\", \"USGS\"])}\n",
    "data = pd.read_csv(gauge_data_path, header=2, parse_dates=[\"Date\"])\n",
    "data.set_index(\"Date\", inplace=True)\n",
    "\n",
    "for idx, column in enumerate(data.columns):\n",
    "    key = (metadata[\"River Station\"][idx], metadata[\"STAGE or FLOW\"][idx])\n",
    "    if key not in grouped_data: grouped_data[key] = []\n",
    "    grouped_data[key].append(data[column])\n",
    "\n",
    "def plot_grouped_data_bokeh(grouped_data):\n",
    "    output_file(os.path.join(folder_path, \"Combined_Data_Plots.html\"), title=\"Time Series Plots by River Station and Series Type\")\n",
    "\n",
    "    plots = []\n",
    "\n",
    "    for key in grouped_data:\n",
    "        p = figure(width=800, height=700, x_axis_type=\"datetime\", title=f\"{key[0]} - {key[1]}\")\n",
    "\n",
    "        legend_items = []\n",
    "\n",
    "        for idx, series in enumerate(grouped_data[key]):\n",
    "            if \"Gauge\" in series.name:\n",
    "                plan_name = series.name\n",
    "            else:\n",
    "                split_name = series.name.split('/')\n",
    "                if len(split_name) >= 2:\n",
    "                    plan_name = split_name[-2]\n",
    "                else:\n",
    "                    plan_name = \"Unknown\"\n",
    "\n",
    "            source = ColumnDataSource(data=dict(x=series.index, y=series.values, plan_name=[plan_name] * len(series)))\n",
    "            color = Category20[20][idx % 20]\n",
    "            line = p.line(x='x', y='y', source=source, line_width=2, color=color)\n",
    "            legend_items.append(LegendItem(label=plan_name, renderers=[line]))\n",
    "\n",
    "            hover = HoverTool(tooltips=[(\"Plan Name\", \"@plan_name\"), (\"Date\", \"@x{%F %T}\"), (\"Value\", \"@y{0.000}\")], formatters={\"@x\": \"datetime\"}, renderers=[line])\n",
    "            p.add_tools(hover)\n",
    "\n",
    "        legend = Legend(items=legend_items, location=\"top_right\")\n",
    "        p.add_layout(legend)\n",
    "\n",
    "        p.xaxis.axis_label = 'Date'\n",
    "        unit = \"CFS\" if key[1] == \"FLOW\" else \"FT\"\n",
    "        p.yaxis.axis_label = f'Values ({unit})'\n",
    "\n",
    "        plots.append([p])\n",
    "\n",
    "    layout = gridplot(plots)\n",
    "    save(layout)\n",
    "plot_grouped_data_bokeh(grouped_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RASDataExtract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
